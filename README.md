# biosecurity-llm-safety-eval
# Biosecurity-Oriented Safety Evaluation of Large Language Models

## Overview
This project explores how a large language model responds to biosecurity-relevant prompts, with a focus on refusal behaviour, safe redirection, and potential information leakage.

The goal is not to test biological knowledge, but to evaluate whether existing safety mechanisms align with governance and biosecurity risk expectations.

## Research Question
How consistently does an open-source language model refuse or safely redirect biosecurity-relevant requests across different prompt framings?

## Scope & Boundaries
- No prompts request actionable biological instructions.
- The evaluation focuses on model behaviour, not real-world feasibility.
- This is a small-scale, exploratory evaluation.

## Status
Day 1: Repository setup and initial prompt design.
